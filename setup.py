from setuptools import setup

setup(
    name='autograd',
    version='1.1.6',
    description='Efficiently computes derivatives of numpy code.',
    author='Dougal Maclaurin and David Duvenaud and Matthew Johnson',
    author_email="maclaurin@physics.harvard.edu, duvenaud@cs.toronto.edu, mattjj@csail.mit.edu",
    packages=['autograd', 'autograd.numpy', 'autograd.numpy.compat', 'autograd.numpy.lib', 'autograd.scipy', 'autograd.scipy.stats'],
    install_requires=['numpy>=1.10', 'scipy>=0.17', 'future>=0.15.2'],
    setup_requires=['numpy>=1.10', 'scipy>=0.17'],
    keywords=['Automatic differentiation', 'backpropagation', 'gradients',
              'machine learning', 'optimization', 'neural networks',
              'Python', 'Numpy', 'Scipy'],
    url='https://github.com/HIPS/autograd',
    license='MIT',
    classifiers=['Development Status :: 4 - Beta',
                 'License :: OSI Approved :: MIT License',
                 'Programming Language :: Python :: 2.7',
                 'Programming Language :: Python :: 3.5'],
)
